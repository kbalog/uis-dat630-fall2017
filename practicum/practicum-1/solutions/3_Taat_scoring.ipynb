{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term-at-a-time scoring\n",
    "\n",
    "  - Implement term-at-a-time scoring using vector space retrieval with TFIDF term weighting\n",
    "  - Use normalized frequencies for TF weight, i.e., $tf_{t,d}=\\frac{f_{t,d}}{|d|}$, where $f_{t,d}$ is the number of occurrences of term $t$ in document $d$ and $|d|$ is the document length (=total number of terms).\n",
    "  - Compute IDF values using the following formula: $idf_{t}=\\log \\frac{N}{n_t}$, where $N$ is the total number of document and $n_t$ is the number of documents that contain term $t$.  (Use base 10 for the logarithm to get the same values as for the paper-based exercise.)\n",
    "  - Compare the results against the scores from Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td_matrix = {\n",
    "    \"beijing\": [0, 1, 0, 0, 1],\n",
    "    \"dish\": [0, 1, 0, 0, 1],\n",
    "    \"duck\": [3, 2, 2, 0, 1],\n",
    "    \"rabbit\": [0, 0, 1, 1, 0],\n",
    "    \"recipe\": [0, 0, 1, 1, 1],\n",
    "    \"roast\": [0, 0, 0, 0, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of documents is set manually for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_DOCS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the corresponding inverted index\n",
    "\n",
    "The postings hold (docID, freq) pairs. docID indices start from 0\n",
    "\n",
    "`doclen` stores the document length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beijing': [(1, 1), (4, 1)],\n",
      " 'dish': [(1, 1), (4, 1)],\n",
      " 'duck': [(0, 3), (1, 2), (2, 2), (4, 1)],\n",
      " 'rabbit': [(2, 1), (3, 1)],\n",
      " 'recipe': [(2, 1), (3, 1), (4, 1)],\n",
      " 'roast': []}\n"
     ]
    }
   ],
   "source": [
    "inv_idx = {}\n",
    "doclen = {}\n",
    "for term, vec in td_matrix.items():\n",
    "    inv_idx[term] = []\n",
    "    for doc_id, freq in enumerate(vec):\n",
    "        if freq > 0:\n",
    "            inv_idx[term].append((doc_id, freq))\n",
    "            doclen[doc_id] = doclen.get(doc_id, 0) + freq\n",
    "\n",
    "pprint(inv_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This class provides access to the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InvIndex(object):\n",
    "    def __init__(self, idx_contents):\n",
    "        self.idx = idx_contents\n",
    "    \n",
    "    def terms(self):\n",
    "        return self.idx.keys()\n",
    "    \n",
    "    def postings(self, term):\n",
    "        return self.idx.get(term, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create index object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = InvIndex(inv_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-at-a-time scoring\n",
    "\n",
    "$Score(q,d) = \\sum_{t \\in q} w_{t,q} \\times w_{t,d}$\n",
    "\n",
    "where $w_{t,d}=\\frac{tfidf_{t,d}}{\\sqrt{\\sum_{t} tfidf_{t,d}^2}}$ and $w_{t,q}=\\frac{tfidf_{t,q}}{\\sqrt{\\sum_{t} tfidf_{t,q}^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDF calculation\n",
    "\n",
    "$IDF(t) = \\log \\frac{N}{n_t}$\n",
    "\n",
    "where $N$ is the total number of documents and $n_t$ is the number of documents that contain term t.\n",
    "Note that $n_t$ is the length of the posting list of the term in the inverted index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(term):\n",
    "    return math.log(NUM_DOCS / len(idx.postings(term))) if len(idx.postings(term)) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-computing document normalizers\n",
    "\n",
    "$\\sqrt{\\sum_{t} tfidf_{t,d}^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docnorm = {}\n",
    "# summation part\n",
    "for term in idx.terms():\n",
    "    for (doc_id, freq) in idx.postings(term): \n",
    "        tf = freq / doclen[doc_id]\n",
    "        tfidf = tf * idf(term)\n",
    "        docnorm[doc_id] = docnorm.get(doc_id, 0) + tfidf**2\n",
    "\n",
    "# sqrt part\n",
    "for doc_id in docnorm.keys():\n",
    "    docnorm[doc_id] = math.sqrt(docnorm[doc_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_tt(query):\n",
    "    scores = {}  # score accumulator\n",
    "    \n",
    "    # computing query normalizer\n",
    "    # note that this could also be ignored as it does not affect the ranking\n",
    "    qnorm = 0\n",
    "    for term in set(query):\n",
    "        tf = query.count(term) / len(query)\n",
    "        tfidf = tf * idf(term)\n",
    "        qnorm += tfidf**2\n",
    "    qnorm = math.sqrt(qnorm)\n",
    "    \n",
    "    # term-at-a-time scoring\n",
    "    for term in query:\n",
    "        for (doc_id, freq) in idx.postings(term): \n",
    "            tf_td = freq / doclen[doc_id]\n",
    "            tfidf_td = tf_td * idf(term)  # doc tfidf score\n",
    "            tf_tq = 1 / len(query)\n",
    "            tfidf_tq = tf_tq * idf(term)  # query tfidf score\n",
    "            score_term = tfidf_tq * tfidf_td / (qnorm * docnorm[doc_id])\n",
    "            scores[doc_id] = scores.get(doc_id, 0) + score_term\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = [\"beijing\", \"duck\", \"recipe\"]\n",
    "scores = score_tt(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D5: 0.76\n",
      "D2: 0.639\n",
      "D3: 0.295\n",
      "D4: 0.232\n",
      "D1: 0.208\n"
     ]
    }
   ],
   "source": [
    "for doc_id, score in sorted(scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(\"D\" + str(doc_id + 1) + \":\", round(score, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
