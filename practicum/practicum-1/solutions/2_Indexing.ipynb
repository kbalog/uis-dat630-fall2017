{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an inverted index\n",
    "\n",
    "  - You are given a sample (1000 documents) from the [The Reuters-21578 data collection](http://www.daviddlewis.com/resources/testcollections/reuters21578/) in `data/reuters21578-000.xml`\n",
    "  - The code that parses the XML and extract a list of preprocessed terms (tokenized, lowercased, stopwords removed) is already given.\n",
    "  - You are also given an InvIndex class that manages the posting lists operations.\n",
    "  - Build an inverted index from the input collection with the term frequencies stored.\n",
    "  - Save the inverted index to a text file. E.g., `termID docID1:freq1 docID2:freq2 ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = [\"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\", \"if\", \"in\", \"into\", \"is\", \"it\", \"no\", \"not\", \"of\", \"on\", \"or\", \"such\", \"that\", \"the\", \"their\", \"then\", \"there\", \"these\", \"they\", \"this\", \"to\", \"was\", \"will\", \"with\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stripping tags inside <> using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def striptags(text):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub('', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse input text and return a list of indexable terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(text):\n",
    "    terms = []\n",
    "    # Replace specific characters with space\n",
    "    chars = [\"'\", \".\", \":\", \",\", \"!\", \"?\", \"(\", \")\"]\n",
    "    for ch in chars:\n",
    "        if ch in text:\n",
    "            text = text.replace(ch, \" \")\n",
    "\n",
    "    # Remove tags\n",
    "    text = striptags(text)\n",
    "\n",
    "    # Tokenization\n",
    "    for term in text.split():  # default behavior of the split is to split on one or more whitespaces\n",
    "        # Lowercasing\n",
    "        term = term.lower()\n",
    "        # Stopword removal\n",
    "        if term in stopwords:\n",
    "            continue\n",
    "        terms.append(term)\n",
    "\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the input document collection\n",
    "\n",
    "  - The collection is given as a single XML file. \n",
    "  - Each document is inside `<REUTERS ...> </REUTERS>`.\n",
    "  - We extract the contents of the `<DATE>`, `<TITLE>`, and `<BODY>` tags.\n",
    "  - After each extracted document, the provided callback function is called and all document data is passed in a single dict argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_collection(input_file, callback):\n",
    "    xmldoc = minidom.parse(input_file)\n",
    "    # Iterate documents in the XML file\n",
    "    itemlist = xmldoc.getElementsByTagName(\"REUTERS\")\n",
    "    doc_id = 0\n",
    "    for doc in itemlist:\n",
    "        doc_id += 1\n",
    "        date = doc.getElementsByTagName(\"DATE\")[0].firstChild.nodeValue\n",
    "        # Skip documents without a title or body\n",
    "        if not (doc.getElementsByTagName(\"TITLE\") and doc.getElementsByTagName(\"BODY\")):\n",
    "            continue\n",
    "        title = doc.getElementsByTagName(\"TITLE\")[0].firstChild.nodeValue\n",
    "        body = doc.getElementsByTagName(\"BODY\")[0].firstChild.nodeValue\n",
    "        callback({\n",
    "            \"doc_id\": doc_id,\n",
    "            \"date\": date,\n",
    "            \"title\": title,\n",
    "            \"body\": body\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints a document's contents (used as a callback function passed to `process_collection`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_doc(doc):\n",
    "    if doc[\"doc_id\"] <= 5:  # print only the first 5 documents\n",
    "        print(\"docID:\", doc[\"doc_id\"])\n",
    "        print(\"date:\", doc[\"date\"])\n",
    "        print(\"title:\", doc[\"title\"])\n",
    "        print(\"body:\", doc[\"body\"])\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docID: 1\n",
      "date: 26-FEB-1987 15:01:01.79\n",
      "title: BAHIA COCOA REVIEW\n",
      "body: Showers continued throughout the week in\n",
      "the Bahia cocoa zone, alleviating the drought since early\n",
      "January and improving prospects for the coming temporao,\n",
      "although normal humidity levels have not been restored,\n",
      "Comissaria Smith said in its weekly review.\n",
      "    The dry period means the temporao will be late this year.\n",
      "    Arrivals for the week ended February 22 were 155,221 bags\n",
      "of 60 kilos making a cumulative total for the season of 5.93\n",
      "mln against 5.81 at the same stage last year. Again it seems\n",
      "that cocoa delivered earlier on consignment was included in the\n",
      "arrivals figures.\n",
      "    Comissaria Smith said there is still some doubt as to how\n",
      "much old crop cocoa is still available as harvesting has\n",
      "practically come to an end. With total Bahia crop estimates\n",
      "around 6.4 mln bags and sales standing at almost 6.2 mln there\n",
      "are a few hundred thousand bags still in the hands of farmers,\n",
      "middlemen, exporters and processors.\n",
      "    There are doubts as to how much of this cocoa would be fit\n",
      "for export as shippers are now experiencing dificulties in\n",
      "obtaining +Bahia superior+ certificates.\n",
      "    In view of the lower quality over recent weeks farmers have\n",
      "sold a good part of their cocoa held on consignment.\n",
      "    Comissaria Smith said spot bean prices rose to 340 to 350\n",
      "cruzados per arroba of 15 kilos.\n",
      "    Bean shippers were reluctant to offer nearby shipment and\n",
      "only limited sales were booked for March shipment at 1,750 to\n",
      "1,780 dlrs per tonne to ports to be named.\n",
      "    New crop sales were also light and all to open ports with\n",
      "June/July going at 1,850 and 1,880 dlrs and at 35 and 45 dlrs\n",
      "under New York july, Aug/Sept at 1,870, 1,875 and 1,880 dlrs\n",
      "per tonne FOB.\n",
      "    Routine sales of butter were made. March/April sold at\n",
      "4,340, 4,345 and 4,350 dlrs.\n",
      "    April/May butter went at 2.27 times New York May, June/July\n",
      "at 4,400 and 4,415 dlrs, Aug/Sept at 4,351 to 4,450 dlrs and at\n",
      "2.27 and 2.28 times New York Sept and Oct/Dec at 4,480 dlrs and\n",
      "2.27 times New York Dec, Comissaria Smith said.\n",
      "    Destinations were the U.S., Covertible currency areas,\n",
      "Uruguay and open ports.\n",
      "    Cake sales were registered at 785 to 995 dlrs for\n",
      "March/April, 785 dlrs for May, 753 dlrs for Aug and 0.39 times\n",
      "New York Dec for Oct/Dec.\n",
      "    Buyers were the U.S., Argentina, Uruguay and convertible\n",
      "currency areas.\n",
      "    Liquor sales were limited with March/April selling at 2,325\n",
      "and 2,380 dlrs, June/July at 2,375 dlrs and at 1.25 times New\n",
      "York July, Aug/Sept at 2,400 dlrs and at 1.25 times New York\n",
      "Sept and Oct/Dec at 1.25 times New York Dec, Comissaria Smith\n",
      "said.\n",
      "    Total Bahia sales are currently estimated at 6.13 mln bags\n",
      "against the 1986/87 crop and 1.06 mln bags against the 1987/88\n",
      "crop.\n",
      "    Final figures for the period to February 28 are expected to\n",
      "be published by the Brazilian Cocoa Trade Commission after\n",
      "carnival which ends midday on February 27.\n",
      " Reuter\n",
      "\n",
      "--\n",
      "docID: 2\n",
      "date: 26-FEB-1987 15:02:20.00\n",
      "title: STANDARD OIL <SRD> TO FORM FINANCIAL UNIT\n",
      "body: Standard Oil Co and BP North America\n",
      "Inc said they plan to form a venture to manage the money market\n",
      "borrowing and investment activities of both companies.\n",
      "    BP North America is a subsidiary of British Petroleum Co\n",
      "Plc <BP>, which also owns a 55 pct interest in Standard Oil.\n",
      "    The venture will be called BP/Standard Financial Trading\n",
      "and will be operated by Standard Oil under the oversight of a\n",
      "joint management committee.\n",
      "\n",
      " Reuter\n",
      "\n",
      "--\n",
      "docID: 3\n",
      "date: 26-FEB-1987 15:03:27.51\n",
      "title: TEXAS COMMERCE BANCSHARES <TCB> FILES PLAN\n",
      "body: Texas Commerce Bancshares Inc's Texas\n",
      "Commerce Bank-Houston said it filed an application with the\n",
      "Comptroller of the Currency in an effort to create the largest\n",
      "banking network in Harris County.\n",
      "    The bank said the network would link 31 banks having\n",
      "13.5 billion dlrs in assets and 7.5 billion dlrs in deposits.\n",
      "       \n",
      " Reuter\n",
      "\n",
      "--\n",
      "docID: 4\n",
      "date: 26-FEB-1987 15:07:13.72\n",
      "title: TALKING POINT/BANKAMERICA <BAC> EQUITY OFFER\n",
      "body: BankAmerica Corp is not under\n",
      "pressure to act quickly on its proposed equity offering and\n",
      "would do well to delay it because of the stock's recent poor\n",
      "performance, banking analysts said.\n",
      "    Some analysts said they have recommended BankAmerica delay\n",
      "its up to one-billion-dlr equity offering, which has yet to be\n",
      "approved by the Securities and Exchange Commission.\n",
      "    BankAmerica stock fell this week, along with other banking\n",
      "issues, on the news that Brazil has suspended interest payments\n",
      "on a large portion of its foreign debt.\n",
      "    The stock traded around 12, down 1/8, this afternoon,\n",
      "after falling to 11-1/2 earlier this week on the news.\n",
      "    Banking analysts said that with the immediate threat of the\n",
      "First Interstate Bancorp <I> takeover bid gone, BankAmerica is\n",
      "under no pressure to sell the securities into a market that\n",
      "will be nervous on bank stocks in the near term.\n",
      "    BankAmerica filed the offer on January 26. It was seen as\n",
      "one of the major factors leading the First Interstate\n",
      "withdrawing its takeover bid on February 9.\n",
      "    A BankAmerica spokesman said SEC approval is taking longer\n",
      "than expected and market conditions must now be re-evaluated.\n",
      "    \"The circumstances at the time will determine what we do,\"\n",
      "said Arthur Miller, BankAmerica's Vice President for Financial\n",
      "Communications, when asked if BankAmerica would proceed with\n",
      "the offer immediately after it receives SEC approval.\n",
      "    \"I'd put it off as long as they conceivably could,\" said\n",
      "Lawrence Cohn, analyst with Merrill Lynch, Pierce, Fenner and\n",
      "Smith.\n",
      "    Cohn said the longer BankAmerica waits, the longer they\n",
      "have to show the market an improved financial outlook.\n",
      "    Although BankAmerica has yet to specify the types of\n",
      "equities it would offer, most analysts believed a convertible\n",
      "preferred stock would encompass at least part of it.\n",
      "    Such an offering at a depressed stock price would mean a\n",
      "lower conversion price and more dilution to BankAmerica stock\n",
      "holders, noted Daniel Williams, analyst with Sutro Group.\n",
      "    Several analysts said that while they believe the Brazilian\n",
      "debt problem will continue to hang over the banking industry\n",
      "through the quarter, the initial shock reaction is likely to\n",
      "ease over the coming weeks.\n",
      "    Nevertheless, BankAmerica, which holds about 2.70 billion\n",
      "dlrs in Brazilian loans, stands to lose 15-20 mln dlrs if the\n",
      "interest rate is reduced on the debt, and as much as 200 mln\n",
      "dlrs if Brazil pays no interest for a year, said Joseph\n",
      "Arsenio, analyst with Birr, Wilson and Co.\n",
      "    He noted, however, that any potential losses would not show\n",
      "up in the current quarter.\n",
      "    With other major banks standing to lose even more than\n",
      "BankAmerica if Brazil fails to service its debt, the analysts\n",
      "said they expect the debt will be restructured, similar to way\n",
      "Mexico's debt was, minimizing losses to the creditor banks.\n",
      " Reuter\n",
      "\n",
      "--\n",
      "docID: 5\n",
      "date: 26-FEB-1987 15:10:44.60\n",
      "title: NATIONAL AVERAGE PRICES FOR FARMER-OWNED RESERVE\n",
      "body: The U.S. Agriculture Department\n",
      "reported the farmer-owned reserve national five-day average\n",
      "price through February 25 as follows (Dlrs/Bu-Sorghum Cwt) -\n",
      "         Natl   Loan           Release   Call\n",
      "         Avge   Rate-X  Level    Price  Price\n",
      " Wheat   2.55   2.40       IV     4.65     --\n",
      "                            V     4.65     --\n",
      "                           VI     4.45     --\n",
      " Corn    1.35   1.92       IV     3.15   3.15\n",
      "                            V     3.25     --\n",
      " X - 1986 Rates.\n",
      "\n",
      "          Natl   Loan          Release   Call\n",
      "          Avge   Rate-X  Level   Price  Price\n",
      " Oats     1.24   0.99        V    1.65    -- \n",
      " Barley   n.a.   1.56       IV    2.55   2.55\n",
      "                             V    2.65    -- \n",
      " Sorghum  2.34   3.25-Y     IV    5.36   5.36\n",
      "                             V    5.54    -- \n",
      "    Reserves I, II and III have matured. Level IV reflects\n",
      "grain entered after Oct 6, 1981 for feedgrain and after July\n",
      "23, 1981 for wheat. Level V wheat/barley after 5/14/82,\n",
      "corn/sorghum after 7/1/82. Level VI covers wheat entered after\n",
      "January 19, 1984.  X-1986 rates. Y-dlrs per CWT (100 lbs).\n",
      "n.a.-not available.\n",
      " Reuter\n",
      "\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "process_collection(\"reuters21578-000.xml\", print_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted index\n",
    "\n",
    "  - The inverted index is an object with methods for adding and fetching postings.\n",
    "  - The data is stored in a map, where keys are terms and values are lists of postings.\n",
    "  - Each posting is an object that holds the doc_id and an optional payload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Posting(object):\n",
    "    def __init__(self, doc_id, payload=None):\n",
    "        self.doc_id = doc_id\n",
    "        self.payload = payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InvIndex(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.index = {}\n",
    "\n",
    "    # Add a document to the posting list of a term\n",
    "    def add_posting(self, term, doc_id, payload=None):\n",
    "        if term not in self.index:  # if term not in index, initialize empty posting list\n",
    "            self.index[term] = []\n",
    "        # append new posting to the posting list\n",
    "        self.index[term].append(Posting(doc_id, payload))\n",
    "\n",
    "    # Get the posting list for a given term\n",
    "    def get_postings(self, term):\n",
    "        if term in self.index:\n",
    "            return self.index[term]\n",
    "        return None\n",
    "\n",
    "    # Returns all unique terms in the index\n",
    "    def get_terms(self):\n",
    "        return self.index.keys() \n",
    "    \n",
    "    # Saves the index to a textfile\n",
    "    def write_to_file(self, filename_index):\n",
    "        f = open(filename_index, \"w\")\n",
    "        for term, postings in self.index.items():\n",
    "            f.write(term)\n",
    "            for posting in postings:\n",
    "                f.write(\" \" + str(posting.doc_id))\n",
    "                if posting.payload is not None:\n",
    "                    f.write(\":\" + str(posting.payload))\n",
    "            f.write(\"\\n\")\n",
    "        f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating an inverted index from the input collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = InvIndex()\n",
    "\n",
    "def index_doc(doc):\n",
    "    #print(\"docID:\", doc[\"doc_id\"])        \n",
    "    text = doc[\"title\"] + \" \" + doc[\"body\"]\n",
    "    terms = parse(text)  # list of terms in the document\n",
    "    tc = Counter(terms) # dict with term counts\n",
    "    for term, freq in tc.items():\n",
    "        ind.add_posting(term, doc[\"doc_id\"], freq)\n",
    "\n",
    "process_collection(\"reuters21578-000.xml\", index_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving inverted index to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind.write_to_file(\"index.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "  - How much space does the inverted index occupy?\n",
    "  - How much space would be needed if the same information was stored in a document-term matrix?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
