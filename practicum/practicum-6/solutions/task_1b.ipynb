{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicum 6: Classification - Alternative techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives:\n",
    "\n",
    "  - Implementing a Naive Bayes classifier\n",
    "  - Using various classifiers implemented in scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implementing a Naive Bayes classifier\n",
    "\n",
    "  - Load the Iris dataset and divide it into to 2/3 training and 1/3 test sets.  \n",
    "  - Implement a Naive Bayes classifier\n",
    "   * a) Use categorical attributes by discretizing each attribute into three equally-sized bins: low, medium, high.\n",
    "   * b) Use continuous attributes and assume a Gaussian (normal) distribution. Estimate the parameters of the distribution (mean and variance) from the training data (you'll have different parameters for each attribute)!\n",
    "  - Compare the performance of the two solutions in terms of accuracy and error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1B) Implement a Naive Bayes classifier\n",
    " \n",
    "   - We use continuous attributes and assume a Gaussian (normal) distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pprint\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four attributes in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ATTRS = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier using continuous attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NB(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    def train(self, attributes, labels):\n",
    "        self.model = {}\n",
    "        ccounter = Counter(labels)\n",
    "        numclasses = len(ccounter)\n",
    "        for l, freq in ccounter.items():\n",
    "            # class prior probabilities P(Y)\n",
    "            self.model[l] = {'P(Y)': freq / len(labels)}\n",
    "            # estimate mean and variance for each attribute and for each class\n",
    "            for a in ATTRS:\n",
    "                # collect values of attribute `a` when the target class is `l`\n",
    "                # and make it a numpy array\n",
    "                vals = np.array([attributes[i][a] for i in range(len(attributes)) if labels[i] == l])                                   \n",
    "                self.model[l][a] = {'mean': np.mean(vals), 'var': np.var(vals)}\n",
    "                                \n",
    "        #pprint.pprint(self.model)  # print model\n",
    "    \n",
    "    def apply(self, attributes):\n",
    "        if not self.model:\n",
    "            raise Exception(\"Model has not been trained\")\n",
    "        # P(Y|X) \\propto P(Y) * P(X_1|Y) * ... * P(X_n|Y)\n",
    "        # in log space: \n",
    "        # log P(Y|X) \\propto log P(Y) + log P(X_1|Y) + ... + log P(X_n|Y)\n",
    "        maxp = float(\"-inf\") \n",
    "        maxl = None\n",
    "        for l, p in self.model.items():\n",
    "            prob = math.log(p['P(Y)'])  # log P(Y)\n",
    "            expl = \"P(\" + l + \")=\" + str(prob)  # explanation string (only for debugging)\n",
    "            for a in ATTRS:                \n",
    "                pxy = normpdf(attributes[a], p[a]['mean'], p[a]['var'])\n",
    "                prob += math.log(pxy)  # + log P(X_i|Y)\n",
    "                expl += \" * P(\" + a + '=' + str(attributes[a]) + \"|\" + l +\")=\" + str(prob)\n",
    "            #print(expl)  # debug\n",
    "            if prob > maxp:\n",
    "                maxp = prob\n",
    "                maxl = l\n",
    "         \n",
    "        return maxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the probability density function for Gaussian distribution with a given mean and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normpdf(x, mean, var):\n",
    "    denom = (2*math.pi*var)**.5\n",
    "    num = math.exp(-(float(x)-float(mean))**2/(2*var))\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    with open(filename, 'rt') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        i = 0\n",
    "        for row in csvreader:\n",
    "            if len(row) == 5:\n",
    "                i += 1\n",
    "                instance = {ATTRS[i]: float(row[i]) for i in range(4)}  # first four values are attributes\n",
    "                label = row[4]  # 5th value is the class label\n",
    "                if i % 3 == 0:  # test instance\n",
    "                    test_x.append(instance)\n",
    "                    test_y.append(label)\n",
    "                else:  # train instance\n",
    "                    train_x.append(instance)\n",
    "                    train_y.append(label)\n",
    "                    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And predictions evaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(predictions, true_labels):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == true_labels[i]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "\n",
    "    print(\"Accuracy:   \", correct / len(predictions))\n",
    "    print(\"Error rate: \", incorrect / len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = load_data(\"data/iris.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = NB()\n",
    "nb.train(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for instance in test_x:\n",
    "    label = nb.apply(instance)\n",
    "    predictions.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:    0.94\n",
      "Error rate:  0.06\n"
     ]
    }
   ],
   "source": [
    "evaluate(predictions, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
