{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicum 6: Classification - Alternative techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives:\n",
    "\n",
    "  - Implementing a Naive Bayes classifier\n",
    "  - Using various classifiers implemented in scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "  - [Matplotlib plotting framework](http://matplotlib.org/api/pyplot_api.html)\n",
    "    * [How to make beautiful data visualizations in Python with matplotlib](http://www.randalolson.com/2014/06/28/how-to-make-beautiful-data-visualizations-in-python-with-matplotlib/)\n",
    "  - [Numpy](http://www.python-course.eu/numpy.php)\n",
    "    * [Numpy arrays](http://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html#numpy.array)\n",
    "    * [Numpy statistics](http://docs.scipy.org/doc/numpy/reference/routines.statistics.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implementing a Naive Bayes classifier\n",
    "\n",
    "  - Load the Iris dataset and divide it into to 2/3 training and 1/3 test sets.  \n",
    "  - Implement a Naive Bayes classifier\n",
    "   * a) Use categorical attributes by discretizing each attribute into three equally-sized bins: low, medium, high.\n",
    "   * b) Use continuous attributes and assume a Gaussian (normal) distribution. Estimate the parameters of the distribution (mean and variance) from the training data (you'll have different parameters for each attribute)!\n",
    "  - Compare the performance of the two solutions in terms of accuracy and error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1A) Implement a Naive Bayes classifier\n",
    " \n",
    "   - We use categorical attributes by discretizing each attribute into three equally-sized bins: low, medium, high.\n",
    "   - We need to apply smoothing to avoid zero probabilities.\n",
    "   - Additionally, we compute probabilities in the log space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pprint\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four attributes in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ATTRS = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the Naive Bayes classifier using categorical attributes, in a class with methods for learning (train) and applying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NB(object):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    def train(self, attributes, labels):\n",
    "        self.model = {}\n",
    "        # TODO    \n",
    "    \n",
    "    def apply(self, attributes):\n",
    "        if not self.model:\n",
    "            raise Exception(\"Model has not been trained\")\n",
    "        label = \"Iris-setosa\"\n",
    "        # TODO\n",
    "        return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a data loading in a way to obtain the attributes set and class labels for each the training and the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    with open(filename, 'rt') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',')\n",
    "        i = 0\n",
    "        for row in csvreader:\n",
    "            if len(row) == 5:\n",
    "                i += 1\n",
    "                instance = {ATTRS[i]: float(row[i]) for i in range(4)}  # first four values are attributes\n",
    "                label = row[4]  # 5th value is the class label\n",
    "                if i % 3 == 0:  # test instance\n",
    "                    test_x.append(instance)\n",
    "                    test_y.append(label)\n",
    "                else:  # train instance\n",
    "                    train_x.append(instance)\n",
    "                    train_y.append(label)\n",
    "                    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define how to evaluate the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(predictions, true_labels):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == true_labels[i]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "\n",
    "    print(\"\\tAccuracy:   \", correct / len(predictions))\n",
    "    print(\"\\tError rate: \", incorrect / len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretization. We need to replace numerical values with labels 'low', 'medium', 'high' such that 1/3 of the values are assigned 'low', 1/3 of the values are assigned 'medium', and 1/3 of the values are assigned 'high'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discretize(attributes):\n",
    "    attrs2 = [{} for _ in range(len(attributes))]  # initialize list of empty dicts\n",
    "    for a in ATTRS:\n",
    "        # find thresholds\n",
    "        values = np.array([x[a] for x in attributes])\n",
    "        # TODO\n",
    "\n",
    "    return attrs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = load_data(\"data/iris.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discretize attribute values.\n",
    "\n",
    "Importantly, we do it on the entire data set (training and testing), to ensure that values are assigned to the same bins in the train and in the test part. We then split back the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2 = discretize(train_x + test_x)\n",
    "train_x2 = x2[:len(train_x)]\n",
    "test_x2 = x2[-len(test_x):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = NB()\n",
    "nb.train(train_x2, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for instance in test_x2:\n",
    "    label = nb.apply(instance)\n",
    "    predictions.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate(predictions, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
